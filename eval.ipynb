{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a05410cf-7ce2-4c0b-b890-8d7b5db30e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from supervoice_gpt import SupervoiceGPT, Tokenizer\n",
    "from train_config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "643b57d0-a798-4c58-ad76-4e97f417114d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "tokenizer = Tokenizer(config, \"tokenizer_text.model\")\n",
    "model = SupervoiceGPT(config)\n",
    "checkpoint = torch.load(f'./output/pre.pt', map_location=\"cpu\")\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d28b485-c49d-48b8-8ccc-d19b004b670a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Input\n",
    "# input = torch.tensor([tokenizer.encode(\"What, time?\") + [0,0], tokenizer.encode(\"What, time?\") + [1, 0]])\n",
    "# input_lengths = torch.tensor([len(tokenizer.encode(\"What, time?\")), len(tokenizer.encode(\"What, time?\")) + 1])\n",
    "\n",
    "# # Output\n",
    "# output_tokens = torch.tensor([tokenizer.encode_phonemes([\"<s>\", \"</s>\", \"</s>\"]), tokenizer.encode_phonemes([\"<s>\", \"</s>\", \"</s>\"])])\n",
    "# output_durations = torch.tensor([[0, 1, 3], [0, 1, 3]])\n",
    "# output_lengths = torch.tensor([2, 3])\n",
    "# print(input)\n",
    "# print(output_tokens)\n",
    "# print(output_durations)\n",
    "\n",
    "# model(\n",
    "#     input = input, \n",
    "#     input_lengths = input_lengths,\n",
    "#     output_tokens = output_tokens,\n",
    "#     output_durations = output_durations,\n",
    "#     output_lengths = output_lengths\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd6c7833-e426-4c8b-81e3-364c512bd260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('m', 9), ('aj', 9), ('•', 0), ('ɲ', 10), ('ej', 17), ('m', 7), ('•', 0), ('ɪ', 5), ('z', 8), ('•', 0), ('æ', 13), ('d', 4), ('ə', 6), ('m', 14)]\n"
     ]
    }
   ],
   "source": [
    "tokens = model.generate(\"My name is Adam\", tokenizer, max_new_tokens = 64, top_k = 6)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57115615-639b-4516-ac9b-422561ffed76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "•: 0.8524270057678223\n",
      "dʲ: 0.017651574686169624\n",
      "i: 0.014367952011525631\n",
      "ɹ: 0.013692270964384079\n",
      "iː: 0.01132174301892519\n",
      "z: 0.010743619874119759\n",
      "ej: 0.008898080326616764\n",
      "ɫ: 0.007960399612784386\n",
      "j: 0.006422969978302717\n",
      "ɲ: 0.004551313351839781\n"
     ]
    }
   ],
   "source": [
    "input = \"Hey, you?\"\n",
    "ctx_tokens = ['ç', 'ɪ']\n",
    "ctx_durations = [8, 10]\n",
    "probs, p = model.predict_next(input, ctx_tokens, ctx_durations, tokenizer)\n",
    "for i in range(len(probs)):\n",
    "    print(p[i] + \": \"+ str(probs[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557d9a12-c68a-4f97-935a-0b4652fbceaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
